{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emoji_Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otvlxc5QSvcp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "##***Get the Emoji Package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7jKTmM0TP6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5ceb53eb-33de-4660-b149-0f1205c60d35"
      },
      "source": [
        "pip install emoji"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=399e3f6557c878f5b742b7dc8400a3fc8fb8af50d4320d7426040ae32ad4a001\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIEHmjytToLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yes1UFlTtPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji.EMOJI_UNICODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbwpCinCUP4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_dict= {\n",
        "        '0' : '\\u2764\\uFE0F',\n",
        "        '1' : ':baseball:',\n",
        "        '2' : ':grinning_face_with_big_eyes:',\n",
        "        '3' : ':disappointed_face:',\n",
        "        '4' : ':fork_and_knife:'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDvKLLnYVFHy",
        "colab_type": "code",
        "outputId": "110d6803-12b4-48a4-f686-ba6d3371d0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "for i in emoji_dict.values():\n",
        "    print(emoji.emojize(i))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ù§Ô∏è\n",
            "‚öæ\n",
            "üòÉ\n",
            "üòû\n",
            "üç¥\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY55phzFXaij",
        "colab_type": "text"
      },
      "source": [
        "##Processing a Custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa1UjPz6XfBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('train_emoji.csv',header=None)\n",
        "test = pd.read_csv('test_emoji.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LInA2r-geh7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train= train.iloc[:,0].values\n",
        "x_test= test.iloc[:,0].values\n",
        "\n",
        "y_test = test.iloc[:,1].values\n",
        "y_train= train.iloc[:,1].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgc4Oc4XxaZc",
        "colab_type": "code",
        "outputId": "d03f976e-8197-4180-9c92-c3a0436959cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "for i in range(5):\n",
        "    print(x_train[i],emoji.emojize(emoji_dict[str(y_train[i])]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never talk to me again üòû\n",
            "I am proud of your achievements üòÉ\n",
            "It is the worst day in my life üòû\n",
            "Miss you so much ‚ù§Ô∏è\n",
            "food is life üç¥\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPrZfgJFT4PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train,num_classes=5)\n",
        "y_test = to_categorical(y_test,num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHXCjLwy00El",
        "colab_type": "text"
      },
      "source": [
        "## Embedding the Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3rmaBOA03pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('glove.6B.50d.txt',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOmkJAj60_69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gloVe_coeff={}\n",
        "c=1\n",
        "for line in f:\n",
        "    values= line.split()\n",
        "    word = values[0]\n",
        "    coeff = np.asarray(values[1:],dtype='float')\n",
        "    gloVe_coeff[word]= coeff\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw8iK0124RiI",
        "colab_type": "code",
        "outputId": "d39a28db-470d-42c4-e216-299323af6b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "gloVe_coeff['eat'].shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYi4S1nZ6eZj",
        "colab_type": "text"
      },
      "source": [
        "##Converting Sentences into Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVQOX94M6hpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embedding_output(X):\n",
        "    maxLen=10\n",
        "    emb_dim= 50\n",
        "    embedding_out = np.zeros((X.shape[0],maxLen,emb_dim))\n",
        "    for i in range(X.shape[0]):\n",
        "        X[i] = X[i].split()\n",
        "        for j in range(len(X[i])):\n",
        "            try:\n",
        "                embedding_out[i][j] = gloVe_coeff[X[i][j].lower()]\n",
        "            except:\n",
        "                embedding_out[i][j] = np.zeros((emb_dim,))\n",
        "    return embedding_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4XgRMYzKziO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "71713ac0-76e5-4fab-8d38-96a4175070bc"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It', 'is', 'the', 'worst', 'day', 'in', 'my', 'life']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvfSgLJXJYov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix_train = embedding_output(x_train)\n",
        "embedding_matrix_test = embedding_output(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWTbZcR9J3Lf",
        "colab_type": "code",
        "outputId": "d633c7cf-e597-431b-bae2-772929161cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(embedding_matrix_test.shape)\n",
        "print(embedding_matrix_train.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56, 10, 50)\n",
            "(132, 10, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSNbviEnLXAe",
        "colab_type": "text"
      },
      "source": [
        "## Building the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e3uanTvLa9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "classifier =  Sequential()\n",
        "classifier.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
        "classifier.add(Dropout(rate=0.5))\n",
        "\n",
        "classifier.add(LSTM(64,input_shape=(10,50)))\n",
        "classifier.add(Dense(5))\n",
        "classifier.add(Activation('softmax'))\n",
        "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1Ry79SmSEFS",
        "colab_type": "text"
      },
      "source": [
        "##Training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prtNtkvOUQR_",
        "colab_type": "code",
        "outputId": "3df6dea1-8bfa-4ed1-f5e9-80484e29c794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.h5',monitor='val_loss',verbose=True,save_best_only=True)\n",
        "stop = EarlyStopping(monitor='val_acc',patience=20)\n",
        "\n",
        "hist=classifier.fit(embedding_matrix_train,y_train,epochs=200,validation_split=0.2,batch_size=64,shuffle=True,callbacks=[checkpoint,stop])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 27 samples\n",
            "Epoch 1/200\n",
            "105/105 [==============================] - 0s 649us/step - loss: 0.4634 - acc: 0.8857 - val_loss: 1.1777 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.17772, saving model to best_model.h5\n",
            "Epoch 2/200\n",
            "105/105 [==============================] - 0s 462us/step - loss: 0.4579 - acc: 0.8667 - val_loss: 1.1188 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.17772 to 1.11876, saving model to best_model.h5\n",
            "Epoch 3/200\n",
            "105/105 [==============================] - 0s 472us/step - loss: 0.4131 - acc: 0.8857 - val_loss: 1.0475 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.11876 to 1.04752, saving model to best_model.h5\n",
            "Epoch 4/200\n",
            "105/105 [==============================] - 0s 481us/step - loss: 0.4143 - acc: 0.8667 - val_loss: 1.0115 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.04752 to 1.01150, saving model to best_model.h5\n",
            "Epoch 5/200\n",
            "105/105 [==============================] - 0s 549us/step - loss: 0.3725 - acc: 0.9048 - val_loss: 1.0753 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.01150\n",
            "Epoch 6/200\n",
            "105/105 [==============================] - 0s 673us/step - loss: 0.3222 - acc: 0.9238 - val_loss: 1.0924 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.01150\n",
            "Epoch 7/200\n",
            "105/105 [==============================] - 0s 529us/step - loss: 0.3400 - acc: 0.8667 - val_loss: 1.1673 - val_acc: 0.7037\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.01150\n",
            "Epoch 8/200\n",
            "105/105 [==============================] - 0s 490us/step - loss: 0.2851 - acc: 0.9238 - val_loss: 1.2549 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.01150\n",
            "Epoch 9/200\n",
            "105/105 [==============================] - 0s 516us/step - loss: 0.2960 - acc: 0.9048 - val_loss: 1.2571 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.01150\n",
            "Epoch 10/200\n",
            "105/105 [==============================] - 0s 489us/step - loss: 0.2909 - acc: 0.9333 - val_loss: 1.1026 - val_acc: 0.5926\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.01150\n",
            "Epoch 11/200\n",
            "105/105 [==============================] - 0s 547us/step - loss: 0.2359 - acc: 0.9429 - val_loss: 1.0827 - val_acc: 0.5926\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.01150\n",
            "Epoch 12/200\n",
            "105/105 [==============================] - 0s 496us/step - loss: 0.1870 - acc: 0.9524 - val_loss: 1.1745 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.01150\n",
            "Epoch 13/200\n",
            "105/105 [==============================] - 0s 497us/step - loss: 0.1792 - acc: 0.9714 - val_loss: 1.3561 - val_acc: 0.5556\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.01150\n",
            "Epoch 14/200\n",
            "105/105 [==============================] - 0s 487us/step - loss: 0.1819 - acc: 0.9333 - val_loss: 1.4599 - val_acc: 0.5926\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.01150\n",
            "Epoch 15/200\n",
            "105/105 [==============================] - 0s 502us/step - loss: 0.1467 - acc: 0.9524 - val_loss: 1.4044 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.01150\n",
            "Epoch 16/200\n",
            "105/105 [==============================] - 0s 483us/step - loss: 0.1294 - acc: 0.9714 - val_loss: 1.3676 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.01150\n",
            "Epoch 17/200\n",
            "105/105 [==============================] - 0s 526us/step - loss: 0.1332 - acc: 0.9619 - val_loss: 1.3742 - val_acc: 0.6296\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.01150\n",
            "Epoch 18/200\n",
            "105/105 [==============================] - 0s 480us/step - loss: 0.0970 - acc: 0.9810 - val_loss: 1.3321 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.01150\n",
            "Epoch 19/200\n",
            "105/105 [==============================] - 0s 493us/step - loss: 0.0946 - acc: 0.9810 - val_loss: 1.3111 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.01150\n",
            "Epoch 20/200\n",
            "105/105 [==============================] - 0s 474us/step - loss: 0.0780 - acc: 0.9905 - val_loss: 1.3434 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.01150\n",
            "Epoch 21/200\n",
            "105/105 [==============================] - 0s 496us/step - loss: 0.0873 - acc: 0.9714 - val_loss: 1.3429 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.01150\n",
            "Epoch 22/200\n",
            "105/105 [==============================] - 0s 518us/step - loss: 0.0705 - acc: 0.9905 - val_loss: 1.3976 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.01150\n",
            "Epoch 23/200\n",
            "105/105 [==============================] - 0s 499us/step - loss: 0.0845 - acc: 0.9810 - val_loss: 1.4335 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.01150\n",
            "Epoch 24/200\n",
            "105/105 [==============================] - 0s 484us/step - loss: 0.0592 - acc: 0.9905 - val_loss: 1.5453 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.01150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf_HujvbciyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.load_weights('best_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVxP6wQ9YhEj",
        "colab_type": "code",
        "outputId": "37d981bc-818d-422d-d165-a75d8c54c773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "classifier.evaluate(embedding_matrix_test,y_test)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 0s 312us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2734816244670324, 0.6071428656578064]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-robKdULa87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=classifier.predict_classes(embedding_matrix_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9IQxbk_L0Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4acce246-49e2-418a-87a3-dbd6a5b070f9"
      },
      "source": [
        "for i in range(30):\n",
        "    print(' '.join(x_test[i]))\n",
        "    print(emoji.emojize(emoji_dict[str(np.argmax(y_test[i]))]))\n",
        "    print(emoji.emojize(emoji_dict[str(pred[i])]))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want to eat\n",
            "üç¥\n",
            "üç¥\n",
            "he did not answer\n",
            "üòû\n",
            "üòû\n",
            "he got a raise\n",
            "üòÉ\n",
            "üòû\n",
            "she got me a present\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n",
            "ha ha ha it was so funny\n",
            "üòÉ\n",
            "üòÉ\n",
            "he is a good friend\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n",
            "I am upset\n",
            "‚ù§Ô∏è\n",
            "üòû\n",
            "We had such a lovely dinner tonight\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n",
            "where is the food\n",
            "üç¥\n",
            "üç¥\n",
            "Stop making this joke ha ha ha\n",
            "üòÉ\n",
            "üòÉ\n",
            "where is the ball\n",
            "‚öæ\n",
            "‚öæ\n",
            "work is hard\n",
            "üòû\n",
            "üòÉ\n",
            "This girl is messing with me\n",
            "üòû\n",
            "‚ù§Ô∏è\n",
            "are you serious ha ha\n",
            "üòÉ\n",
            "üòû\n",
            "Let us go play baseball\n",
            "‚öæ\n",
            "‚öæ\n",
            "This stupid grader is not working\n",
            "üòû\n",
            "üòû\n",
            "work is horrible\n",
            "üòû\n",
            "üòû\n",
            "Congratulation for having a baby\n",
            "üòÉ\n",
            "üòû\n",
            "stop messing around\n",
            "üòû\n",
            "üòû\n",
            "any suggestions for dinner\n",
            "üç¥\n",
            "üç¥\n",
            "I love taking breaks\n",
            "‚ù§Ô∏è\n",
            "‚ù§Ô∏è\n",
            "you brighten my day\n",
            "üòÉ\n",
            "‚ù§Ô∏è\n",
            "I boiled rice\n",
            "üç¥\n",
            "üç¥\n",
            "she is a bully\n",
            "üòû\n",
            "‚ù§Ô∏è\n",
            "Why are you feeling bad\n",
            "üòû\n",
            "üòû\n",
            "I am upset\n",
            "üòû\n",
            "üòû\n",
            "I worked during my birthday\n",
            "üòû\n",
            "üòÉ\n",
            "My grandmother is the love of my life\n",
            "‚ù§Ô∏è\n",
            "‚ù§Ô∏è\n",
            "enjoy your break\n",
            "üòÉ\n",
            "üç¥\n",
            "valentine day is near\n",
            "‚ù§Ô∏è\n",
            "üòÉ\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}